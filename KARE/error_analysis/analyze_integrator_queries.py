#!/usr/bin/env python3
"""
Analyze query distributions generated by integrator analysts.
Focuses on mortality_assessment and survival_assessment queries from debate logs.
"""

import os
import re
import json
import pandas as pd
import numpy as np
from pathlib import Path
from collections import defaultdict

# Configuration
BASE_PATH_RAG = "/data/wang/junh/githubs/Debate/KARE/results/rag"

# Integrator roles
INTEGRATOR_ROLES = ["mortality_assessment", "survival_assessment"]

def estimate_tokens(text):
    """Estimate token count from text (approximately 4 chars per token)."""
    if not text:
        return 0
    return len(text) / 4.0


def extract_queries_from_log(log_path, role):
    """
    Extract all queries for a specific integrator role from a debate log.
    
    Queries can appear in several formats:
    1. PARSED TOOL CALL: tool='retrieve', query='...'
    2. retrieve("query text")
    3. query = "query text" followed by retrieve(query)
    
    Returns list of query strings.
    """
    try:
        with open(log_path, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()
    except Exception as e:
        print(f"Error reading {log_path}: {e}")
        return []
    
    # Split log into sections by role
    # Look for patterns like "MORTALITY TOOL RESPONSE:" or "SURVIVAL TOOL RESPONSE:"
    if role == "mortality_assessment":
        # Find the mortality assessment section
        mortality_pattern = r'MORTALITY TOOL RESPONSE:.*?(?=SURVIVAL TOOL RESPONSE:|INTEGRATOR STEP 2:|$)'
        sections = re.findall(mortality_pattern, content, re.DOTALL)
    else:  # survival_assessment
        # Find the survival assessment section
        survival_pattern = r'SURVIVAL TOOL RESPONSE:.*?(?=INTEGRATOR STEP 2:|FINAL INTEGRATION|$)'
        sections = re.findall(survival_pattern, content, re.DOTALL)
    
    queries = []
    
    for section in sections:
        # Method 1: PARSED TOOL CALL format
        # Example: "MORTALITY PARSED TOOL CALL: tool='retrieve', query='acute myocardial infarction mortality risk factors'"
        parsed_pattern = r'PARSED TOOL CALL:\s*tool=["\']retrieve["\'],\s*query=["\']([^"\']+)["\']'
        parsed_matches = re.findall(parsed_pattern, section)
        queries.extend(parsed_matches)
        
        # Method 2: Direct retrieve() calls
        # Example: retrieve("acute myocardial infarction mortality risk factors")
        retrieve_pattern = r'retrieve\s*\(\s*["\']([^"\']+)["\']\s*\)'
        retrieve_matches = re.findall(retrieve_pattern, section)
        queries.extend(retrieve_matches)
        
        # Method 3: Variable assignment pattern
        # Example: query = "..." followed by retrieve(query)
        var_pattern = r'query\s*=\s*["\']([^"\']+)["\']'
        var_matches = re.findall(var_pattern, section)
        queries.extend(var_matches)
    
    # Deduplicate while preserving order
    seen = set()
    unique_queries = []
    for q in queries:
        if q not in seen and len(q.strip()) > 0:
            seen.add(q)
            unique_queries.append(q.strip())
    
    return unique_queries


def analyze_model_queries(model_dir):
    """
    Analyze queries for a single model directory.
    
    Returns dict with statistics for each integrator role.
    """
    model_path = os.path.join(BASE_PATH_RAG, model_dir)
    debate_logs_path = os.path.join(model_path, 'debate_logs')
    
    if not os.path.exists(debate_logs_path):
        print(f"  Warning: No debate_logs directory found for {model_dir}")
        return None
    
    # Storage for queries by role
    role_queries = {role: [] for role in INTEGRATOR_ROLES}
    patient_query_counts = {role: defaultdict(int) for role in INTEGRATOR_ROLES}
    
    # Get all debate log files
    log_files = [f for f in os.listdir(debate_logs_path) 
                 if f.startswith('debate_responses_') and f.endswith('.log')]
    
    print(f"  Processing {len(log_files)} debate logs...")
    
    for log_file in log_files:
        log_path = os.path.join(debate_logs_path, log_file)
        patient_id = log_file.replace('debate_responses_', '').replace('.log', '')
        
        for role in INTEGRATOR_ROLES:
            queries = extract_queries_from_log(log_path, role)
            
            if queries:
                role_queries[role].extend(queries)
                patient_query_counts[role][patient_id] = len(queries)
    
    # Calculate statistics for each role
    stats = {}
    
    for role in INTEGRATOR_ROLES:
        queries = role_queries[role]
        
        if not queries:
            stats[role] = {
                'total_queries': 0,
                'total_patients': 0,
                'patients_with_queries': 0,
                'query_lengths': [],
                'length_stats': {}
            }
            continue
        
        # Calculate query lengths in tokens
        query_lengths = [estimate_tokens(q) for q in queries]
        
        # Count patients
        total_patients = len(log_files)
        patients_with_queries = len([p for p, c in patient_query_counts[role].items() if c > 0])
        
        # Calculate statistics
        length_stats = {
            'count': len(query_lengths),
            'mean': np.mean(query_lengths),
            'median': np.median(query_lengths),
            'std': np.std(query_lengths),
            'min': np.min(query_lengths),
            'max': np.max(query_lengths),
            'q25': np.percentile(query_lengths, 25),
            'q75': np.percentile(query_lengths, 75),
        }
        
        # Queries per patient statistics
        queries_per_patient = [c for c in patient_query_counts[role].values() if c > 0]
        if queries_per_patient:
            qpp_stats = {
                'mean': np.mean(queries_per_patient),
                'median': np.median(queries_per_patient),
                'min': np.min(queries_per_patient),
                'max': np.max(queries_per_patient),
            }
        else:
            qpp_stats = {'mean': 0, 'median': 0, 'min': 0, 'max': 0}
        
        stats[role] = {
            'total_queries': len(queries),
            'total_patients': total_patients,
            'patients_with_queries': patients_with_queries,
            'query_lengths': query_lengths,
            'length_stats': length_stats,
            'queries_per_patient': qpp_stats,
            'sample_queries': queries[:5]  # First 5 queries as examples
        }
    
    return stats


def main():
    """Main analysis function."""
    print("=" * 80)
    print("INTEGRATOR QUERY ANALYSIS")
    print("=" * 80)
    print()
    
    # Get all model directories
    model_dirs = [d for d in os.listdir(BASE_PATH_RAG) 
                  if os.path.isdir(os.path.join(BASE_PATH_RAG, d))]
    
    print(f"Found {len(model_dirs)} model directories:\n")
    for i, model_dir in enumerate(model_dirs, 1):
        print(f"  {i}. {model_dir}")
    print()
    
    # Analyze each model
    all_model_stats = {}
    
    for model_dir in model_dirs:
        print(f"\n{'='*80}")
        print(f"ANALYZING: {model_dir}")
        print(f"{'='*80}")
        
        stats = analyze_model_queries(model_dir)
        
        if stats is None:
            continue
        
        all_model_stats[model_dir] = stats
        
        # Print statistics for this model
        for role in INTEGRATOR_ROLES:
            role_stats = stats[role]
            
            print(f"\n{'-'*80}")
            print(f"Role: {role.replace('_', ' ').title()}")
            print(f"{'-'*80}")
            
            print(f"\nCoverage:")
            print(f"  Total patients: {role_stats['total_patients']}")
            print(f"  Patients with queries: {role_stats['patients_with_queries']}")
            print(f"  Coverage: {role_stats['patients_with_queries']/role_stats['total_patients']*100:.1f}%")
            
            print(f"\nQuery Counts:")
            print(f"  Total queries extracted: {role_stats['total_queries']}")
            if role_stats['patients_with_queries'] > 0:
                qpp = role_stats['queries_per_patient']
                print(f"  Queries per patient (with queries):")
                print(f"    Mean: {qpp['mean']:.2f}")
                print(f"    Median: {qpp['median']:.1f}")
                print(f"    Range: {qpp['min']:.0f} - {qpp['max']:.0f}")
            
            if role_stats['total_queries'] > 0:
                ls = role_stats['length_stats']
                print(f"\nQuery Length Distribution (tokens):")
                print(f"  Count: {ls['count']}")
                print(f"  Mean: {ls['mean']:.2f}")
                print(f"  Median: {ls['median']:.2f}")
                print(f"  Std Dev: {ls['std']:.2f}")
                print(f"  Min: {ls['min']:.2f}")
                print(f"  Max: {ls['max']:.2f}")
                print(f"  25th percentile: {ls['q25']:.2f}")
                print(f"  75th percentile: {ls['q75']:.2f}")
                
                print(f"\nSample Queries:")
                for i, query in enumerate(role_stats['sample_queries'], 1):
                    tokens = estimate_tokens(query)
                    print(f"  {i}. [{tokens:.1f} tokens] {query[:80]}{'...' if len(query) > 80 else ''}")
    
    # Comparative analysis across models
    print(f"\n\n{'='*80}")
    print("COMPARATIVE ANALYSIS ACROSS MODELS")
    print(f"{'='*80}\n")
    
    for role in INTEGRATOR_ROLES:
        print(f"\n{role.replace('_', ' ').title()}:")
        print(f"{'-'*80}")
        
        comparison_data = []
        for model_dir in sorted(all_model_stats.keys()):
            stats = all_model_stats[model_dir]
            role_stats = stats[role]
            
            if role_stats['total_queries'] > 0:
                ls = role_stats['length_stats']
                comparison_data.append({
                    'Model': model_dir[:60],  # Truncate long names
                    'Total_Queries': role_stats['total_queries'],
                    'Coverage_%': f"{role_stats['patients_with_queries']/role_stats['total_patients']*100:.1f}",
                    'Mean_Length': f"{ls['mean']:.2f}",
                    'Median_Length': f"{ls['median']:.2f}",
                    'Std_Dev': f"{ls['std']:.2f}",
                    'Min': f"{ls['min']:.2f}",
                    'Max': f"{ls['max']:.2f}",
                })
        
        if comparison_data:
            df = pd.DataFrame(comparison_data)
            print(df.to_string(index=False))
        else:
            print("  No data available")
    
    # Summary statistics
    print(f"\n\n{'='*80}")
    print("SUMMARY STATISTICS")
    print(f"{'='*80}\n")
    
    summary_data = []
    for model_dir in sorted(all_model_stats.keys()):
        stats = all_model_stats[model_dir]
        
        mort_queries = stats['mortality_assessment']['total_queries']
        surv_queries = stats['survival_assessment']['total_queries']
        
        mort_mean = stats['mortality_assessment']['length_stats'].get('mean', 0)
        surv_mean = stats['survival_assessment']['length_stats'].get('mean', 0)
        
        summary_data.append({
            'Model': model_dir[:50],
            'Mortality_Queries': mort_queries,
            'Survival_Queries': surv_queries,
            'Total_Queries': mort_queries + surv_queries,
            'Mortality_Avg_Length': f"{mort_mean:.2f}",
            'Survival_Avg_Length': f"{surv_mean:.2f}",
        })
    
    summary_df = pd.DataFrame(summary_data)
    print(summary_df.to_string(index=False))
    
    print(f"\n{'='*80}")
    print("ANALYSIS COMPLETE")
    print(f"{'='*80}")


if __name__ == "__main__":
    main()
